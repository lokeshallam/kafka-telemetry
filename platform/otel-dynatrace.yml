version: '3.x'
services:

################## ZOOKEEPER ##################

  zoo1:
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION}
    hostname: zoo1.${DOMAIN}
    container_name: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVERS: zoo1.${DOMAIN}:2888:3888
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: DEBUG
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      KAFKA_HEAP_OPTS: "-Xms${ZK_HEAP} -Xmx${ZK_HEAP}"
    volumes:
      - ./volumes/zoo-1/data:/var/lib/zookeeper/data
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "(echo ruok | nc zoo1.${DOMAIN} 2181) | grep -e imok"]
      start_period: 5s
      interval: 20s
      timeout: 10s
      retries: 20

################## BROKERS ##################

  kafka1:
    image: confluentinc/cp-server:${CONFLUENT_VERSION}
    hostname: kafka1.${DOMAIN}
    container_name: kafka1
    ulimits:
      nofile:
        soft: 82920
        hard: 82920
    links:
      - zoo1
    depends_on:
      zoo1:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      # zookeeper
      KAFKA_ZOOKEEPER_CONNECT: zoo1.${DOMAIN}:2181
      KAFKA_ZOOKEEPER_CLIENT_CNXN_SOCKET: org.apache.zookeeper.ClientCnxnSocketNetty
      # listeners
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1.${DOMAIN}:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENERS: INTERNAL://kafka1.${DOMAIN}:29092,EXTERNAL://kafka1.${DOMAIN}:9092
      KAFKA_SECURITY_PROTOCOL: PLAINTEXT
      KAFKA_CONFLUENT_BALANCER_ENABLE: 'true'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      # metrics reporter
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka1:29092
      CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: PLAINTEXT
      # cluster linking
      CONFLUENT_CLUSTER_LINK_METADATA_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_PASSWORD_ENCODER_SECRET: cl-secret
      # logging
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_LOG4J_LOGGERS: kafka.authorizer.logger=INFO
      #KAFKA_OPTS: '-Djavax.net.debug=ssl'
      #KAFKA_JMX_PORT: 9010
      #KAFKA_JMX_HOSTNAME: localhost
      KAFKA_HEAP_OPTS: "-Xms${BROKER_HEAP} -Xmx${BROKER_HEAP}"
    volumes:
      - ./volumes/kafka-1:/var/lib/kafka/data
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "kafka-cluster cluster-id --bootstrap-server kafka1.${DOMAIN}:29092 | grep -e 'Cluster ID: .*'"]
      start_period: 30s
      interval: 10s
      timeout: 10s
      retries: 10

################## SCHEMA REGISTRY ##################

  schema1:
    image: confluentinc/cp-schema-registry:${CONFLUENT_VERSION}
    hostname: schema1.${DOMAIN}
    container_name: schema1
    links:
      - kafka1
    depends_on:
      kafka1:
        condition: service_healthy
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: 'schema1'
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8081'
      # kafka store
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1.${DOMAIN}:29092'
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: 'PLAINTEXT'
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: '_schemas'
      SCHEMA_REGISTRY_KAFKASTORE_ZK_SESSION_TIMEOUT_MS: 60000
      SCHEMA_REGISTRY_KAFKASTORE_TIMEOUT_MS: 10000
      SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT_MS: 120000
      # other
      SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: 'http'
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_GROUP_ID: 'schema-registry'
      SCHEMA_REGISTRY_LEADER_ELIGIBILITY: 'true'
      SCHEMA_REGISTRY_MODE_MUTABILITY: 'true'
      SCHEMA_REGISTRY_DEBUG: 'true'
      KAFKA_HEAP_OPTS: "-Xms${SCHEMA_HEAP} -Xmx${SCHEMA_HEAP}"
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://schema1.${DOMAIN}:8081/subjects"]
      interval: 10s
      timeout: 10s
      retries: 20

################## KAFKA CONNECT ##################

  connect1:
    image: confluentinc/cp-server-connect:${CONFLUENT_VERSION}
    hostname: connect1
    container_name: connect1
    links:
      - schema1
    depends_on:
      schema1:
        condition: service_healthy
    command:
      - bash
      - -c
      - |
        echo "Installing Connectors"
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.2.6
        curl -k -L https://jdbc.postgresql.org/download/postgresql-42.3.1.jar -o /usr/share/java/postgresql-42.3.1.jar
        curl -k -L https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/download/v1.17.0/opentelemetry-javaagent.jar -o /usr/share/java/opentelemetry-javaagent.jar
        #
        echo "Starting Kafka Connect server"
        /etc/confluent/docker/run &
        sleep infinity
    ports:
      - 8083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1.${DOMAIN}:29092'
      CONNECT_SECURITY_PROTOCOL: 'PLAINTEXT'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect1
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: docker-connect-cluster
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      CONNECT_KEY_SUBJECT_NAME_STRATEGY: io.confluent.kafka.serializers.subject.RecordNameStrategy
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      CONNECT_VALUE_SUBJECT_NAME_STRATEGY: io.confluent.kafka.serializers.subject.RecordNameStrategy
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: zoo1.${DOMAIN}:2181
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LISTENERS: http://0.0.0.0:8083
      CONNECT_REST_ADVERTISED_LISTENER: http
      # Set in seconds, this was changed to allow for detection of new topics and partitions quicker by the
      # JDBC sink connector (default is five minutes). Comment out this setting for overall better consumer
      # performance.
      CONNECT_METADATA_MAX_AGE_MS: 60
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR,org.apache.kafka=ERROR,org.apache.hadoop=ERROR,org.apache.parquet=ERROR,io.confluent=ERROR,org.apache.kafka.connect.runtime=ERROR
      #KAFKA_JMX_OPTS: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.port=9010 -Dcom.sun.management.jmxremote.rmi.port=9010 -Djava.rmi.server.hostname=10.0.0.193"
      OTEL_SERVICE_NAME: "connect1"
      OTEL_TRACES_EXPORTER: "otlp"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector.${DOMAIN}:4317"
      OTEL_METRICS_EXPORTER: "none"
      OTEL_TRACES_SAMPLER: "traceidratio"
      OTEL_TRACES_SAMPLER_ARG: "1.0"
      KAFKA_OPTS: >-
        -javaagent:/usr/share/java/opentelemetry-javaagent.jar
      KAFKA_JVM_PERFORMANCE_OPTS: >-
        -server -XX:+UseG1GC -XX:GCTimeRatio=1
        -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
        -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
        -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      KAFKA_HEAP_OPTS: "-Xms${CONNECT_HEAP} -Xmx${CONNECT_HEAP}"
    volumes:
      - ./schemas:/schemas:ro
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://connect1:8083/connectors"]
      start_period: 30s
      interval: 10s
      timeout: 10s
      retries: 10

################## CLIENT ##################

  client:
    image: kafka-client:0.0.1
    build: ./client
    hostname: client.${DOMAIN}
    container_name: client
    links:
      - schema1
    depends_on:
      schema1:
        condition: service_healthy
    command:
      - bash
      - -c
      - |
        touch /tmp/initialized
        tail -f /dev/null
    volumes:
      - ./client/scripts:/scripts:ro
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "find /tmp/initialized"]
      start_period: 60s
      interval: 15s
      timeout: 15s
      retries: 30

################## TELEMETRY ##################

  collector:
    image: otel/opentelemetry-collector:latest
    hostname: collector
    container_name: collector
    links:
      - kafka1
    depends_on:
      jaeger:
        condition: service_started
      kafka1:
        condition: service_healthy
    command: ["--config=/etc/otel-collector-config.yml", ""]
    ports:
      - "1888:1888"   # pprof extension
      - "9010:9010"   # Prometheus metrics exposed by the collector
      - "9011:9011"   # Prometheus exporter metrics
      - "13133:13133" # health_check extension
      - "4317:4317"   # OTLP gRPC receiver
      - "55679:55679" # zpages extension
    volumes:
      - ./otel/otel-collector-dynatrace.yml:/etc/otel-collector-config.yml
    networks:
      - kafka-network

################## APPS ##################

  producer1:
    image: ${REGISTRY}/java-kafka-producer:0.0.1
    hostname: producer1
    container_name: producer1
    links:
      - schema1
    depends_on:
      schema1:
        condition: service_healthy
    ports:
      - "9000:9000"
      - "9100:9100"
    environment:
      CLIENT_ID: producer1
      BOOTSTRAP_URL: kafka1.${DOMAIN}:29092
      SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      TOPIC: demo.customer
      SCHEMA: customer
      PARTITIONS: 5
      MESSAGES: 10000
      BATCH_SIZE: 1
      FREQUENCY_MS: 1000
      PORT: 9000
      OTEL_SERVICE_NAME: "producer1"
      OTEL_RESOURCE_ATTRIBUTES: "service.name=producer1,service.version=0.0.1,mytag=myvalue"
      OTEL_TRACES_EXPORTER: "otlp"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector.${DOMAIN}:4317"
      OTEL_METRICS_EXPORTER: "none"
      OTEL_TRACES_SAMPLER: "traceidratio"
      OTEL_TRACES_SAMPLER_ARG: "1.0"
      JAVA_OPTS: >-
        -Xms1G -Xmx1G
        -javaagent:/agents/opentelemetry-javaagent.jar
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://producer1.${DOMAIN}:9000/actuator/health | grep -e '\"status\":\"UP\"'"]
      interval: 10s
      timeout: 10s
      retries: 20

  kstream1:
    image: ${REGISTRY}/java-kafka-streams:0.0.1
    hostname: kstream1
    container_name: kstream1
    links:
      - producer1
    depends_on:
      producer1:
        condition: service_healthy
    ports:
      - "9001:9001"
      - "9101:9101"
    environment:
      APP_ID: kstream1
      GROUP_ID: kstream1
      BOOTSTRAP_URL: kafka1.${DOMAIN}:29092
      SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      INPUT_TOPIC: demo.customer
      OUTPUT_TOPIC: demo.transform.customer
      ERROR_TOPIC: demo.errors
      STATE_STORE_CLEANUP: false
      IN_MEMORY_STATE: false
      STREAM_TYPE: stateless
      STATE_DIR: /data
      PORT: 9001
      OTEL_SERVICE_NAME: "kstream1"
      OTEL_RESOURCE_ATTRIBUTES: "service.name=kstream1,service.version=0.0.1,mytag=myvalue"
      OTEL_TRACES_EXPORTER: "otlp"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector.${DOMAIN}:4317"
      OTEL_METRICS_EXPORTER: "none"
      OTEL_TRACES_SAMPLER: "traceidratio"
      OTEL_TRACES_SAMPLER_ARG: "1.0"
      JAVA_OPTS: >-
        -Xms1G -Xmx1G
        -javaagent:/agents/opentelemetry-javaagent.jar
    volumes:
      - ./volumes/kstreams-1:/data
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://kstream1.${DOMAIN}:9001/actuator/health | grep -e '\"status\":\"UP\"'"]
      interval: 10s
      timeout: 10s
      retries: 20

  consumer1:
    image: ${REGISTRY}/java-kafka-consumer:0.0.1
    hostname: consumer1
    container_name: consumer1
    links:
      - kstream1
    depends_on:
      kstream1:
        condition: service_healthy
    ports:
      - "9002:9002"
      - "9102:9102"
    environment:
      CLIENT_ID: consumer1
      GROUP_ID: consumer1
      BOOTSTRAP_URL: kafka1.${DOMAIN}:29092
      SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_URL: http://schema1.${DOMAIN}:8081
      TOPIC: demo.transform.customer
      OFFSET_DAYS: 0
      POLL_TIMEOUT_SECS: 30
      PORT: 9002
      OTEL_SERVICE_NAME: "consumer1"
      OTEL_RESOURCE_ATTRIBUTES: "service.name=consumer1,service.version=0.0.1,mytag=myvalue"
      OTEL_TRACES_EXPORTER: "otlp"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://collector.${DOMAIN}:4317"
      OTEL_METRICS_EXPORTER: "none"
      OTEL_TRACES_SAMPLER: "traceidratio"
      OTEL_TRACES_SAMPLER_ARG: "1.0"
      JAVA_OPTS: >-
        -Xms1G -Xmx1G
        -javaagent:/agents/opentelemetry-javaagent.jar
    networks:
      - kafka-network
    healthcheck:
      test: ["CMD", "bash", "-c", "curl http://consumer1.${DOMAIN}:9002/actuator/health | grep -e '\"status\":\"UP\"'"]
      interval: 10s
      timeout: 10s
      retries: 20

networks:
  kafka-network:
    name: ${DOMAIN}

volumes:
  postgres-data:
    name: postgres_volume_name
